---
layout: post
title:  "[번역글] REVEAL'20 Workshop Introduction"
date:   2020-02-11 19:31:29 +0900
categories: RecSys
tags : [Bandit, REVEAL, RL, Counterfactual]
toc: true
toc_sticky: true
---



> [REVEAL'20](https://sites.google.com/view/reveal2020/home) Home을 번역한 글입니다. 문장이 꽤 길고 복문이 많아서 짧은 단문으로 고쳐 썼습니다.

## <mark>주요주장</mark>

1. **추천 시스템은 유저와 시스템이 Interactive하고 multi-step descision making한다는 특징을 살려서 모델링 하자.**

2. **지도학습 기반의 Proxy Offline Metric 대신 Logged Interaction Data를 활용할 수 있는 Counterfactual Evaluation을 하자.**

3. **1,2를 학계에서도 활용할 수 있는 Simulator와 Open datasets을 만들자.**



## <mark>내용</mark>
최신 추천 시스템들은 설계 및 개선이 어려운 것으로 악명이 높습니다. interactive하고 dynamic하기 때문인데요. 사용자와 시스템 간에 발생하는 일련의 상호작용((interactions)에서 다단계 의사 결정 프로세스(multi-step decision making)을 수반하기 때문에 이런 특징을 지니게 됩니다. 상호 작용에서 생기는 보상 신호를 활용하고, 확장 가능하면서 성능이 뛰어난 추천 추론 모델을 만드는 것은  중요한 과제입니다. 전통적으로는 문제를 쉽게 다루기 위해 상호 작용은 종종 독립적인 것으로 간주됩니다. 하지만 추천 시스템을 더욱 개선하기 위해서는 모델에 추천에 대한 delayed effect를 고려해야 하고, 사용자 장기적인 만족을 위한 reasoning과 planning을 고려하기 시작해야 합니다. 이를 위해 워크샵에서는 추천 시스템에 다양한 형태의 사용자 피드백을 효과적으로 적용했거나 사용자의 장기적인 경험을 최적화한 연구를(contributions) 초대합니다.

이러한 대화형 특성 때문에 추천 시스템도 평가하기가 어렵기로 악명이 높습니다. 시스템을 평가할 때, 실무자는 종종 새로운 알고리듬의 오프라인 결과와 온라인 결과 사이에서 상당한 차이를 관찰하기 때문에 A/B 테스트와 같은 온라인 방법에 주로 의존하는 경향이 있습니다. 안타깝게도 온라인 평가가 항상 가능한 것은 아니며 종종 비용이 많이 들기 때문입니다. 반면, 오프라인 평가는 추천 시스템을 비교할 수 있는 확장 가능한 방법을 제공하고 산업 관련 문제에 대한 학술 연구의 참여를 가능하게 합니다.

interactive 하다는 특징 때문에, 추천 시스템을 평가하기 어려운 걸로 악명이 높습니다. 시스템을 평가할 때 실무자는 새로운 알고리즘의 오프라인 결과와 온라인 결과 사이에 상당한 차이를 관찰하게 됩니다. 이 때문에 A/B 테스트와 같은 온라인 방법에 주로 의존하는 경향이 있습니다. 안타깝게도 온라인 평가는 항상 가능한 것도 아니고 비용도 많이 듭니다. 반면 오프라인 평가는 추천 시스템을 비교할 수 있는 Scalable한 방법을 제공하고 아카데미에서 산업 관련 문제를 참여할 수 있게 합니다.

그 동안의 추천 시스템은 Regression Metrics(Mean Squared Error, Log Likelihood), Classifiaction Metrics(Area Under precision/recall Curve), Ranking Metrics(precision@k, NDCG) 같은 지도학습 기반의 Proxy Offline Metrics들을 통해 평가되어 왔습니다. 최근 추천시스템 연구는 Offline A/B 테스팅을 위한 Counterfactual Inference 과의 연결점을 만들고 있습니다. 이를 위해 Logged Interaction Data를 재사용하거나 민감한 개인 정보 문제를 피하기 위해 시뮬레이터를 사용하기도 합니다.

이런 맥락에서, 추천 시스템을 설계하고 평가하는 문제를 다시 생각해보는 워크샵을 구성하기 좋은 시기라 생각합니다. 이를 통해 학계와 산업계를 망라한 커뮤니티가 올바른 문제, 각 사용자에게 가장 영향력있는 추천을 하고 있는지,를 풀고 있는지 확인하려 합니다.

## <mark>워크샵 주제</mark>
이번 워크샵은 열띤 참여가 있었던 [REVEAL’18](https://www.google.com/url?q=https%3A%2F%2Fsites.google.com%2Fview%2Freveal2018%2Fhome&sa=D&sntz=1&usg=AFQjCNFL2KhYCb1UXxD4tkFJITqSXjFgvQ) and [REVEAL’19](https://www.google.com/url?q=https%3A%2F%2Fsites.google.com%2Fview%2Freveal2019%2Fhome&sa=D&sntz=1&usg=AFQjCNGNNg7W6lEu37vasKirngi7nO9wng)의 follow-up 입니다. 우리의 proposal은 다음 주제에 대한 연구를 계속 확장해나가는 것입니다.

- **Reinforcement learning and bandits for recommendation**
- **Robust estimators and counterfactual evaluation**
- **Using simulation for recommender systems evaluation**
- **Open datasets and new offline metrics**

The benefits of this workshop will be:

- **To bridge the gap between academia and industry through new datasets and methods**
- **To increase the productivity of all practitioners in their development of recommender systems**

Organizers:

- [Thorsten Joachims](http://www.google.com/url?q=http%3A%2F%2Fwww.cs.cornell.edu%2Fpeople%2Ftj%2F&sa=D&sntz=1&usg=AFQjCNEPNtqvJjc2x-r4hvCel4PnMrGPhg), Information Science and Computer Science, Cornell University
- [Adith Swaminathan](https://www.google.com/url?q=https%3A%2F%2Fwww.microsoft.com%2Fen-us%2Fresearch%2Fpeople%2Fadswamin%2F&sa=D&sntz=1&usg=AFQjCNHE8Nalw7qbDTckSWLh7GcgQtmhpg), Deep Learning Technology Center, Microsoft Research
- [Maria Dimakopoulou](http://www.google.com/url?q=http%3A%2F%2Fstanford.edu%2F~madima%2F&sa=D&sntz=1&usg=AFQjCNE9JmP_e_OXrgvpDlzaTp8b2F9fNQ) and [Yves Raimond](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fyvesr%2F&sa=D&sntz=1&usg=AFQjCNHfQBa_Urk9aClGqYMrws8FJJsV7A), Netflix Research
- [Olivier Koch](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Folivier-koch%2F&sa=D&sntz=1&usg=AFQjCNGV0YUrkyeS7Cp2KzYOYDY2oxJeiQ) and [Flavian Vasile](https://www.google.com/url?q=https%3A%2F%2Fwww.linkedin.com%2Fin%2Fflavianv%2F&sa=D&sntz=1&usg=AFQjCNHoYB23IuwmKpIO2rRNnIR3W8z3Zg), R&D, Criteo
