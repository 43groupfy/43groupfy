---
title: RecSys & RL - A Deep Reinforcement Learning Framework for News Recommendation
author: Bean
date: 2022-05-01 16:32:00 +0800
categories: [Recommandation System]
tags: [Recommandation System, Reinforcement learning, paper]
layout: post
current: post
class: post-template
subclass: 'post'
navigation: True
cover:  assets/img/post_images/recsys_cover1.jpg
---

## Introduction
딥러닝 모델을 활용한 기존 뉴스 추천 시스템의 취약점
* 다이나믹하게 변하는 뉴스의 특성과 뉴스에 대한 유저의 선호도 변화를 고려할 때, online learning 이 필요하다. 하지만 기존의 뉴스 추천 시스템은 ...
* 기존 추천 시스템은 유저 feedback로 오직 click/no click 정보만 고려했다. 따라서 뉴스를 탐색하면서 실수로 잘못 누른 기사와 정말 읽고 싶어서 찾아서 들어간 기사의 reward는 확실히 달라야하지만 이러한 특성은 잡아내지 못하였다.
* 기존 추천 시스템은 유저에게 유사한 뉴스를 계속 추천하려는 경향이 있다. 그렇지만 이렇게 계속 비슷한 뉴스를 추천해주면 주제에 대한 사용자의 흥미가 쉽게 떨어진다.

## Proposed method
이러한 취약점을 극복하기 위하여 이 논문에서는 DQN을 활용한 다음과 같은 추천시스템을 제안한다.
* 유저와 아이템(뉴스)간의 복잡한 관계를 모델링하는 대신에, online news recommendation의 다이나믹한 특성에 집중하여 future reward를 모델링한다.
(기존의 MAB 방법들과 다름)
* MDP(Markov Decision Process)를 적용하여 이용하여 모델의 future reward를 활용할 수 있다.
* 더 나아가 MDP framework를 continuous state와 action representation와 함께 사용하여 쉽게 확장할 수 있고, 모든 (state, action, reward) tuple을 활용하여 모델 파라미터를 효율적으로 학습할 수 있다.
(기존의 MAP 방법들과 다름)

* Exploration strategy로 Dueling Bandit Gradient Descent exploration strategy를 활용
  * Improve recommendation diversity
  * avoid the harm to recommendation accuracy induced by classical exploration strategies (ex> e-greedy, Upper Confidence Bound)

### Model framework


## Experiment
## Conclusion