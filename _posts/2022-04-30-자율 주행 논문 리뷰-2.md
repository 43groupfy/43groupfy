---
title: RL - Autonomous Driving Based on Modified SAC Algorithm through Imitation Learning Pre-training
author: Bean
date: 2022-04-30 16:32:00 +0800
categories: [Reinforcement learning, Autonomous driving]
tags: [Autonomous driving, Reinforcement learning, paper]
layout: post
current: post
class: post-template
subclass: 'post'
navigation: True
cover:  assets/img/post_images/driving_cover2.jpg
---

This paper is a follow-up to the paper written 2 years ago. Although the core idea is the same, since the previously used DDPG algorithm did not converge well, SAC was used instead.

## Background
&nbsp;

* This paper is based on the previous study with very similar settings but difference
model.
* The DDPG algorithm(previously used) seems to have not much high convergence
during training
* Instead, use SAC(Soft Actor Critic) algorithm
  * Robustness, stability and well-convergence
  * State-of-the-art off-policy actor critic deep reinforcement learning algorithm based on the maximum entropy reinforcement learning framework

## Proposed method
&nbsp;

* Single-Q SAC Algorithm : use SAC with some slight differences due to the method of combining imitation learning and reinforcement learning
  * The original SAC has two target parameters for Q-function
  * However, with previous experiment, the average return over 5 runs of 3 million iterations of SAC algorithm with double-A and SAC algorithm with single-Q are quite similar, so they only use one target parameter for each network and do not update the temperature parameter Î± for simplicity

## Results
&nbsp;
* Although using pure SAC can result in a good performance, it still has a lower
average accumulated reward after 100 episodes than their method.
  <div style="text-align: left">
    <img src="/assets/img/post_images/sc3.png" width="70%"/>
  </div>