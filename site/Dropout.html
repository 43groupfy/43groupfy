<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Dropout (Mathmatical approach)</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Seize the day" />
    <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicons/favicon-32x32.png" type="image/png" />
    <link rel="canonical" href="http://localhost:4000/Dropout" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

    <meta name="google-site-verification" content="X86eN2H5lW1jy6i7OLmOjBAyCf4N8PPVT0sBdIH57LE" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="PIGBEAN Tech blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Dropout (Mathmatical approach)" />
    <meta property="og:description" content="Dropout은 Prevent Multi layer perceptron Overfitting에서와 같이 딥러닝 학습에서 발생하는 문제인 Overfitting을 해소하기 위한 방법 중 하나이다. Solution of Overfitting   일반적으로 머신 러닝에서 the curse of dimensionality라는 이야기를 한다. 요약하면 ‘더 많은 파라미터’, ‘더 복잡한 모델’은 데이터의 수가 적을 경우 거의 암기해버리기 때문에 문제가 된다는 얘기이다. 이런 경우가 Overfitting이라고" />
    <meta property="og:url" content="http://localhost:4000/Dropout" />
    <meta property="og:image" content="http://localhost:4000/assets/img/post_images/ai_cover2.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/false" />
    <meta property="article:author" content="https://www.facebook.com/false" />
    <meta property="article:published_time" content="2022-05-07T17:32:00+09:00" />
    <meta property="article:modified_time" content="2022-05-07T17:32:00+09:00" />
    <meta property="article:tag" content="Ai" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Dropout (Mathmatical approach)" />
    <meta name="twitter:description" content="Dropout은 Prevent Multi layer perceptron Overfitting에서와 같이 딥러닝 학습에서 발생하는 문제인 Overfitting을 해소하기 위한 방법 중 하나이다. Solution of Overfitting   일반적으로 머신 러닝에서 the curse of dimensionality라는 이야기를 한다. 요약하면 ‘더 많은 파라미터’, ‘더 복잡한 모델’은 데이터의 수가 적을 경우 거의 암기해버리기 때문에 문제가 된다는 얘기이다. 이런 경우가 Overfitting이라고" />
    <meta name="twitter:url" content="http://localhost:4000/" />
    <meta name="twitter:image" content="http://localhost:4000/assets/img/post_images/ai_cover2.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="PIGBEAN Tech blog" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Ai" />
    <meta name="twitter:site" content="@false" />
    <meta name="twitter:creator" content="@false" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
        }
        });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "PIGBEAN Tech blog",
        "logo": "http://localhost:4000/assets/img/favicons/android-chrome-256x256.png"
    },
    "url": "http://localhost:4000/Dropout",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:4000/assets/img/post_images/ai_cover2.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:4000/Dropout"
    },
    "description": "Dropout은 Prevent Multi layer perceptron Overfitting에서와 같이 딥러닝 학습에서 발생하는 문제인 Overfitting을 해소하기 위한 방법 중 하나이다. Solution of Overfitting   일반적으로 머신 러닝에서 the curse of dimensionality라는 이야기를 한다. 요약하면 ‘더 많은 파라미터’, ‘더 복잡한 모델’은 데이터의 수가 적을 경우 거의 암기해버리기 때문에 문제가 된다는 얘기이다. 이런 경우가 Overfitting이라고"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Dropout (Mathmatical approach)" href="/feed.xml" />



</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="http://localhost:4000/"><img src="/assets/img/favicons/android-chrome-256x256.png" alt="PIGBEAN Tech blog" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/Catty/">Catty</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-ai post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime=" 7 May 2022"> 7 May 2022</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/ai/'>AI</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Dropout (Mathmatical approach)</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/img/post_images/ai_cover2.jpg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p>Dropout은 <a href="">Prevent Multi layer perceptron Overfitting</a>에서와 같이 딥러닝 학습에서 발생하는 문제인 Overfitting을 해소하기 위한 방법 중 하나이다.</p>

<h2 id="solution-of-overfitting">Solution of Overfitting</h2>
<p> </p>

<p>일반적으로 머신 러닝에서 <code class="language-plaintext highlighter-rouge">the curse of dimensionality</code>라는 이야기를 한다. 요약하면 ‘더 많은 파라미터’, ‘더 복잡한 모델’은 데이터의 수가 적을 경우 거의 암기해버리기 때문에 문제가 된다는 얘기이다.
이런 경우가 Overfitting이라고 불리며, 이러한 Overfitting을 방지하기 위한 방법은 크게 아래 두가지 방법이 있다.</p>

<ul>
  <li>
    <p>데이터 수 늘려주기</p>

    <p>Overfitting의 원인 중 하나는 데이터의 양이 충분하지 않은 것이다. 데이터의 수가 부족하므로 보편적인 분류를 하지 못하고 훈련데이터에 너무 많은 영향을 받게 된다. 따라서 더 많은 데이터로 학습을 돌려주면 Overfitting을 어느 정도 방지할 수 있다. 하지만 보통의 경우 데이터를 수집하는 것이 매우 비싼 과정이기 때문에 이 방법은 사용하기 어렵다.</p>
  </li>
  <li>
    <p>Regularization</p>

    <p>다음으로 regulariztion을 사용하여 Overfitting을 방지할 수 있다. <a href="">Prevent Multi layer perceptron Overfitting</a>에서 소개한 weight decay도 이 regularization 기법에 포함된다. Regularization은 모델이 학습 데이터에 지나치게 의존하지 않도록 panelty를 부과하는 것이다. 깊은(deep) 모델 일 수록 representation 능력이 너무 좋아 쉽게 Overfitting이 될 수 있다. 이를 방지하기 위해 regularization 기법들은 일부러 representation 성능에 제한을 주는 것이다. 이 글의 토픽인 Dropout도 regularization 방법 중 하나이다.</p>
  </li>
</ul>

<p> </p>
<h2 id="committee-machine">Committee Machine</h2>
<p><br />
 </p>
<div style="text-align: left">
   <img src="/assets/img/post_images/dropout3.png" width="100%" />
</div>
<p>Committee Machine은 그림과 같이 서로 다른 network 집단을 만든 다음에 각각 독립적으로 학습시킨 뒤, 마지막에 합쳐서 결과를 내는 방법이다. 이런 방식을 Ensemble average라고 한다. 마치, 전무가 한 명에게 물어보는 것보다 전문가 여러명에게 물어본 후 결과를 취합하면 예상치 못한 bias나 오류를 방지할 수 있는 겻과 같다.</p>

<p> </p>
<h2 id="dropout">Dropout</h2>
<p><br />
 
Committe Machine의 예처럼 학습을 할 때, 서로 다른 학습데이터를 통해 모델을 학습시키거나 모델이 서로 다른 구조를 가지면 학습 성능을 개선할 수 있다. 이런 방법을 Model Combination이라고 한다.
하지만 모델이 복잡한 경우 하나의 모델을 훈련시키는 것도 어려운데 여러개의 네트워크를 훈련시키는 것은 매우 어렵다. 또한 이렇게 학습을 시켰다고 해도 이렇게 학습된 모델을 실행할 때도 연산 시간이 오래걸린다.</p>

<p>따라서 Dropout 기법은 모델을 여러개 만들 지 않고 모델 결합이 여러 형태를 가지게 하여 Model Combination과 비슷한 효과를 내게 한다. 네트워크를 학습하는 동안 랜덤하게 일부 뉴런을 생략해버리면, 뉴런의 조합의 지수함수 만큼 다양한 모델을 학습 시키는 것과 비슷해진다. n개의 뉴런이 있다고 하면 $2^{n}$개의 서로 다른 모델이 생성된다.</p>

<p>학습은 이렇게 시켰더라도, 이렇게 학습된 모델을 실행 시킬 때 생성된 $2^{n}$개의 서로 다른 모델을 따로 실행시키면 똑같이 연산 시간이 매우 오래 걸리는 문제가 있다. 따라서 이렇게 많은 모델을 각각 실행하는 것이 아니라, 어짜피 생략된 모델들이 모두 파라미터를 공유하고 있기 때문에 각각의 뉴런들이 모델에서 존재할 (dropout 하지 않을) 확률을 각각의 가중치에 곱해주는 형태로 한 번만 실행을 한다.</p>

<p>정리하면 아래 그림과 같이 학습 시에는 뉴런은 존재할 확률 p로 학습을 진행하고, 실행할 때는 각각의 network에서 얻어진 가중치에 존재 확률 p를 곱해준다.</p>
<div style="text-align: left">
   <img src="/assets/img/post_images/dropout1.png" width="100%" />
</div>
<div style="text-align: left">
   <img src="/assets/img/post_images/dropout4.png" width="100%" />
</div>

<p> </p>
<h3 id="dropout-효과">Dropout 효과</h3>
<p> 
그렇다면 이런 방식으로 어떻게 regulation 효과를 얻을 수 있는 것일까?</p>

<ul>
  <li>
    <p>co-adaptation 방지</p>

    <p>먼저 학습을 시키다보면, 학습 데이터에 의해 같은 층의 각각의 weight들이 서로 같아지는 경우가 생긴다. 이렇게 되면 이 이상 학습이 진행되어도 이 노드들은 같은 일을 수행하게 되어 불필요한 중복이 생겨 컴퓨팅 파워, 메모리 낭비로 이어진다. 드롭아웃은 임의로 노드들을 생략하는 데 이때, 이러한 상호 적응 중인 노드들 중 일부는 생략하고 일부는 생략하지 않게 되므로 학습 중 상호 적응이 발생한 노드들이 분리될 수 있어서 상호 적응 문제를 회피할 수 있게 된다.</p>
  </li>
  <li>
    <p>hidden neuron들의 activity가 좀 더 드문드문(sparsity) 해진다.</p>
  </li>
</ul>

<h3 id="dropout의-regularization-효과의-수학적-증명-single-linear-unit">Dropout의 regularization 효과의 수학적 증명 (single linear unit)</h3>
<p> 
먼저 non-linear function이 없는 single linear unit에 대하여 dropout의 regularization 효과를 살펴볼 것이다. 이후 non-linear function이 있는 경우를 살펴볼 예정이다. multilayer 로의 확장도 비슷한 방식으로 여러 layer에 대하여 계산하여 얻을 수 있다.</p>

<p>Dropout의 regularization 효과를 확인하기 위하여 Ensemble average를 사용하는 test network error와 training에서 사용되는 $2^{n}$개의 dropout network error을 비교해 볼 것이다. 즉,</p>

\[\begin{cases}
 &amp; E_{ENS} = \frac{1}{2}(t-O_{ENS})^{2} = \frac{1}{2}(t-\sum_{i=1}^{n}p_{i}w_{i}I_{i})^{2} \\
 &amp; E_{D} = \frac{1}{2}(t-O_{D})^{2} = \frac{1}{2}(t-\sum_{i=1}^{n}\delta _{i}w_{i}I_{i})^{2}
\end{cases}\]

<p>을 비교해본다.
만약 test network error와 dropout network error가 거의 같다면 굳이 dropout network을 쓸 이유가 없어진다. 하나의 학습만 진행하는 test network 보다 학습에 훨씬 더 많은 시간이 소요되기 때문이다. 따라서, 이 두 네트워크의 에러를 비교해보는 것이 dropout의 필요성 및 정규화 효과를 확인해볼 수 있는 좋은 방법이 된다.</p>

<p>두 네트워크의 학습 과정을 비교해보기 위하여 gradient를 구하여 비교하였다.</p>

\[\begin{cases}
 &amp; \frac{\partial E_{ENS}}{\partial W_{i}} = -(t-O_{ENS})p_{i}I_{i} \\
 &amp; \frac{\partial E_{D}}{\partial W_{i}} = -(t-O_{D})\delta _{i}I_{i} = -t\delta _{i}I_{i}+w_{i}\delta _{i}^{2}I_{i}^{2}+\sum_{j\neq i}^{}w_{j}\delta _{i}\delta _{j}I_{i}I_{j}
\end{cases}\]

<p>이제, $E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right )$ 와 $E\left ( \frac{\partial E_{ENS}}{\partial w_{i}} \right )$ 를 구해보자.
먼저, $E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right )$ 는</p>

\[E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right ) = -(t-E(O_{D}|\delta _{i}=1) )p_{i}I_{i}\]

<p>이 때,</p>

\[E(\delta _{i}^{2}) = E(\delta _{i})=p_i ~(\because \delta _{i}=0, 1)\]

<p>이므로,</p>

\[E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right ) = -tp_{i}I_{i}+w_{i}p_{i}I_{i}^{2}+\sum_{j\neq i}^{}w_{i}p_{i}p_{j}I_{i}I_{j}\]

<p>또한, $\sum w_{i}p_{i}p_{j}I_{i}I_{j}=\sum_{k=1}^{n}p_{k}w_{k}I_{k} \times p_{i}I_{i} - w_{i}I_{i}^{2}p_{i} = O_{ENS}P_{i}I_{i}-w_{i}I_{i}^{2}p_{i}$ 이므로</p>

\[E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right ) = -(t-O_{ENS})p_{i}I_{i} + w_{i}I_{i}^{2}(p_{i})(1-p_{i})
\\
= \frac{\partial E_{ENS}}{\partial w_{i}}+w_{i}I_{i}^{2}Var\delta _{i}=\frac{\partial E_{ENS}}{\partial W_{i}}+w_{i}Var\left ( \delta _{i}I_{i} \right )\]

\[\therefore  E_{D} = E_{ENS} + \frac{1}{2}\sum_{i=1}^{n}w_{i}^{2}I_{i}^{2}Var\delta _{i}\]

<p>이 때, 이 식은 weight decay에서 $E=E_{0}+\alpha \left| w\right|^{2}$ 와 같이 generalization capability를 높이기 위하여 추가 loss term 을 더해준 것과 같은 형태이다. 따라서 Single linear unit에서, dropout network는 inference network(Ensemble average network)에 weight decay term을 추가한 것과 같다. 따라서 weight decay term을 추가하는 것과 동일하게 generalization 효과가 생긴다.</p>

<h3 id="dropout-regularization-효과의-수학적-증명-single-sigmoidal-unit">Dropout regularization 효과의 수학적 증명 (single sigmoidal unit)</h3>
<p> 
비슷한 방식으로, 이번에는 non-linear function이 있는 경우를 살펴보자.  non-linear function이 없는 경우와 마찬가지로 $\frac{\partial E_{ENS}}{\partial w_{i}}$ 와 $\frac{\partial E_{D}}{\partial w_{i}}$ 를 비교해서 확인할 수 있다.</p>

<p>이 때, Error는 cross entropy loss function을 이용하였고, 따라서 다음의 에러 텀을 구할 수 있다.</p>

\[E = -(t-logO + (1-t)log(1-O)), ~~O=\sigma(s)=\frac{1}{(1+ce^{-\lambda s})}\]

<p>이 때, $ \frac{\partial E}{\partial w} = \frac{\partial E}{\partial O} \frac{\partial O}{\partial S} \frac{\partial S}{\partial w} $ 이고,</p>

<p>$ \frac{\partial E}{\partial O} = -t \frac{1}{O} + (1-t) \frac{1}{1-O}, ~~\frac{\partial O}{\partial S} = \lambda O (1-O) $ 이므로,</p>

<p>$ \frac{\partial E}{\partial w} = -\lambda(t-O)\frac{\partial S}{\partial w} $ 이다.</p>

<p>따라서 두 gradient는,</p>

\[\begin{cases}
 &amp; \frac{\partial E_{ENS}}{\partial w_{i}} = \lambda(t-\sigma(U))p_{i}I_{i} = - \lambda  \left ( t-\sigma \left ( \sum_{j}^{}w_{j}p_{j}I_{j} \right ) \right )p_{i}I_{i} \\
 &amp; \frac{\partial E_{D}}{\partial w_{i}}  = \lambda(t- O)\delta _{i}I_{i} = - \lambda  \left ( t-\sigma \left ( \sum_{j}^{}w_{j}\delta _{j}I_{j} \right ) \right )\delta _{i}I_{i}
\end{cases}\]

<p>이 된다.</p>

<p>마지막으로 $E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right )$ 을 계산하면,</p>

\[E\left ( \frac{\partial E_{D}}{\partial w_{i}} \right ) = -\lambda \left ( t - E \left [ \sigma \left ( \sum_{j}^{} w_{j}\delta _{j} I_{j} | \delta_{i} = 1 \right ) \right ] \right )p_{i}I_{i}
\\
\approx -\lambda\left ( t-\sigma \left ( \sum_{j}^{} w_{j}p_{j}I_{j} - w_{i}p_{i}I_{i} + w_{i}I_{i}\right ) \right )p_{i}I_{i}
\\
\approx -\lambda \left ( t-\sigma(S_{ENS}) - \sigma^{'}(S_{ENS})I_{i}w_{i}(1-p_{i}) \right )p_{i}I_{i}
\\
= \frac{\partial E_{ENS}}{\partial w_{i}}+\lambda \sigma ^{'}(U)w_{i}Var(\delta _{i}I_{i}))\]

\[\therefore  E_{D} = E_{ENS} + \frac{1}{2} \lambda \sigma ^{'}(U)\sum_{i=1}^{n}w_{i}^{2}I_{i}^{2}Var\left ( \delta _{i} \right )\]

<p>따라서, 이 경우도 만찬가지로 Ensemble average network에 weight decay term을 사용한 것과 형태가 같고, 따라서 정규화 역할을 한다.</p>

<p><br />
 
참고 내용 출처 :</p>
<ul>
  <li>KAIST EE538 Neural Networks lecture</li>
  <li><a href="https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=laonple&amp;logNo=220818841217">https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=laonple&amp;logNo=220818841217</a></li>
  <li><a href="https://hyeonnii.tistory.com/254">https://hyeonnii.tistory.com/254</a></li>
</ul>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Bean" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/Bean">Beanie</a></h4>
                                
                                    <p>Hello, I’m Beanie, always pondering and crafting services to make life fun and convenient</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/Bean">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'http://localhost:4000/Dropout';
                            var this_page_identifier = '/Dropout';
                            var this_page_title = 'Dropout (Mathmatical approach)';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://Beanie.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/img/style/bean3.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; PIGBEAN Tech blog &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/ai/">Ai</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Transformer">Transformer</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Implement-Bidirectional-Associative-Memory">Bidirectional Associative Memory 구현</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Implement-Multi-layer-perceptron-(from-scratch)">Implement Multi layer perceptron (from scratch)</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/ai/">
                                
                                    See all 6 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Implement-Q-learning-&-Double-Q-learning">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/ai_cover.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Implement-Q-learning-&-Double-Q-learning">
                <header class="post-card-header">
                    
                        
                            
                               <span class="post-card-tags">Rl</span>
                            
                        
                            
                                <span class="post-card-tags">Coding</span>
                            
                        
                    

                    <h2 class="post-card-title">Q-learning & Double Q-learning 구현</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Q-learning과 Double Q-learning
 

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Bean/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      5 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/RecSys-based-on-MF">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/recsys_cover2.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/RecSys-based-on-MF">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">추천시스템</span>
                            
                        
                    

                    <h2 class="post-card-title">Matrix Factorization(MF) 기반 추천시스템</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>추천시스템의 기초적인 내용을 잘 알지 못한채로 추천 알고리즘을 구현하는 논문들을 몇개 읽다보니 구현의 기반이 되는 중요한 원리를 계속 놓치고 있는 듯한 기분이 들었다. 그래서 Python을 이용한 개인화 추천시스템 책을 사서 읽고, 또 다양한</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Bean/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      6 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="http://localhost:4000/">
            
                <img src="/assets/img/favicons/favicon-32x32.png" alt="PIGBEAN Tech blog icon" />
            
            <span>PIGBEAN Tech blog</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Dropout (Mathmatical approach)</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Dropout+%28Mathmatical+approach%29&amp;url=https://beanie00.github.io/Dropout"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://beanie00.github.io/Dropout"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://localhost:4000/">PIGBEAN Tech blog</a> &copy; 2022</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69281367-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
