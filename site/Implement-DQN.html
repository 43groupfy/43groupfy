<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Deep Q-Network(DQN) 구현</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="Seize the day" />
    <link rel="shortcut icon" href="http://localhost:4000/assets/img/favicons/favicon-32x32.png" type="image/png" />
    <link rel="canonical" href="http://localhost:4000/Implement-DQN" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

    <meta name="google-site-verification" content="X86eN2H5lW1jy6i7OLmOjBAyCf4N8PPVT0sBdIH57LE" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="PIGBEAN Tech blog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Deep Q-Network(DQN) 구현" />
    <meta property="og:description" content="  DQN 이란?     DQN 구현   Environment 먼저, 이번 DQN 구현은 제공받은 2개의 GridWorld 환경을 기반으로 진행하였다. 먼저 첫번째 GridWorld는 그림과 같다. 그림에서 볼 수 있듯이 이 환경은 노란 동그라미, 빨간 네모, 녹색 네모로 구성되어 있다. 각각을 살펴보면, 노란 동그라미 : agent의 움직임을 나타낸다. 빨간 네모 : 폭탄이" />
    <meta property="og:url" content="http://localhost:4000/Implement-DQN" />
    <meta property="og:image" content="http://localhost:4000/assets/img/post_images/ai_cover.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/false" />
    <meta property="article:author" content="https://www.facebook.com/false" />
    <meta property="article:published_time" content="2022-05-16T13:02:00+09:00" />
    <meta property="article:modified_time" content="2022-05-16T13:02:00+09:00" />
    <meta property="article:tag" content="Rl" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Deep Q-Network(DQN) 구현" />
    <meta name="twitter:description" content="  DQN 이란?     DQN 구현   Environment 먼저, 이번 DQN 구현은 제공받은 2개의 GridWorld 환경을 기반으로 진행하였다. 먼저 첫번째 GridWorld는 그림과 같다. 그림에서 볼 수 있듯이 이 환경은 노란 동그라미, 빨간 네모, 녹색 네모로 구성되어 있다. 각각을 살펴보면, 노란 동그라미 : agent의 움직임을 나타낸다. 빨간 네모 : 폭탄이" />
    <meta name="twitter:url" content="http://localhost:4000/" />
    <meta name="twitter:image" content="http://localhost:4000/assets/img/post_images/ai_cover.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="PIGBEAN Tech blog" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Rl" />
    <meta name="twitter:site" content="@false" />
    <meta name="twitter:creator" content="@false" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
        tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
        }
        });
    </script>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "PIGBEAN Tech blog",
        "logo": "http://localhost:4000/assets/img/favicons/android-chrome-256x256.png"
    },
    "url": "http://localhost:4000/Implement-DQN",
    "image": {
        "@type": "ImageObject",
        "url": "http://localhost:4000/assets/img/post_images/ai_cover.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://localhost:4000/Implement-DQN"
    },
    "description": "  DQN 이란?     DQN 구현   Environment 먼저, 이번 DQN 구현은 제공받은 2개의 GridWorld 환경을 기반으로 진행하였다. 먼저 첫번째 GridWorld는 그림과 같다. 그림에서 볼 수 있듯이 이 환경은 노란 동그라미, 빨간 네모, 녹색 네모로 구성되어 있다. 각각을 살펴보면, 노란 동그라미 : agent의 움직임을 나타낸다. 빨간 네모 : 폭탄이"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Deep Q-Network(DQN) 구현" href="/feed.xml" />



</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="http://localhost:4000/"><img src="/assets/img/favicons/android-chrome-256x256.png" alt="PIGBEAN Tech blog" /></a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/Catty/">Catty</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-rl tag-coding post ">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="16 May 2022">16 May 2022</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/rl/'>RL</a>,
                            
                        
                            
                               <a href='/tag/coding/'>CODING</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Deep Q-Network(DQN) 구현</h1>
            </header>

            
            <figure class="post-full-image" style="background-image: url(/assets/img/post_images/ai_cover.jpg)">
            </figure>
            

            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <p> </p>
<h2 id="dqn-이란">DQN 이란?</h2>
<p> </p>

<p> </p>
<h2 id="dqn-구현">DQN 구현</h2>
<p> </p>

<h3 id="environment">Environment</h3>
<p>먼저, 이번 DQN 구현은 제공받은 2개의 GridWorld 환경을 기반으로 진행하였다.</p>

<p>먼저 첫번째 GridWorld는 그림과 같다.</p>

<div style="text-align: left">
  <img src="/assets/img/post_images/dqn4.png" width="50%" />
</div>

<p>그림에서 볼 수 있듯이 이 환경은 노란 동그라미, 빨간 네모, 녹색 네모로 구성되어 있다. 각각을 살펴보면,</p>

<ul>
  <li>노란 동그라미 : agent의 움직임을 나타낸다.</li>
  <li>빨간 네모 : 폭탄이 위치해 있으며 agent가 해당 위치로 가면 reward -10을 얻고 다시 episode를 시작한다.</li>
  <li>초록 네모 : 보물이 위치해 있으며 agent가 해당 위치로 가면 reward 20을 얻고 다시 episode를 시작한다.</li>
  <li>빨간 네모, 초록 네모가 없는 공간을 노란 동그라미가 탐색할 때마다 reward -0.1을 얻는다.</li>
</ul>

<p>두번째 GridWorld는 첫번째 GridWorld에 주황 네모가 추가되었다.</p>

<div style="text-align: left">
  <img src="/assets/img/post_images/dqn5.png" width="45%" />
</div>

<ul>
  <li>주황 네모 : 음식 위치해 있으며 agent가 해당 위치로 가면 reward 10을 얻고 다시 episode를 시작한다.</li>
</ul>

<h3 id="dqn-class-구현">DQN class 구현</h3>

<p>이러한 환경에서 잘 동작할 수 있는 DQN을 구현해보자.
DQN 구현은 <strong>neural network 생성</strong>, <strong>action 선택</strong>, <strong>experience replay를 위하여 이전 experience를 메모리에 저장</strong>, <strong>메모리에 포함된 experience를 이용하여 학습</strong>의 과정으로 나눠볼 수 있다.</p>

<ul>
  <li>
    <p><strong>neural network 생성</strong> (<code class="language-plaintext highlighter-rouge">_construct_network()</code> 함수)</p>

    <div style="text-align: left">
  <img src="/assets/img/post_images/dqn3.jpeg" width="80%" />
  </div>

    <p>이 DQN 모델에서 구현한 neural network는 위 다이어그램과 비슷하다. 먼저 input layer에서 n_features size의 입력을 받고 24 크기로 출력을 한다. 이 때, activation 함수로 relu 함수를 사용하였다. 또한 Hidden layer에서는 이전 레이어의 출력을 인풋으로 받아 24 크기로 출력을 한다. 이 때도 마찬가지로 activation 함수로 relu를 사용하였다. 마지막 output layer에서는 n_actions 크기로 출력을 하고 이 때, activation 함수를 linear로 설정하였다. 이렇게 구현한 모델의 코드는 아래와 같다.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
  <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">))</span>
</code></pre></div>    </div>

    <p>이 모델에 n_features 크기의 state 벡터가 들어오면 모델의 prediction으로 얻은 예측된 reward 값과 true reward 값의 에러가 작아지도록 내부 weight 값을 조정한다. 이를 계속 반복하다보면 예측된 reward가 true reward와 같아지는 방향으로 (최적 policy를 찾는 방향으로) 학습되게 된다.</p>

    <p>좀 더 구체적으로 학습 과정을 model.fit()과 model.predict() 함수로 다시 나눌 수 있다. 각각을 살펴보면,
  model.fit(state, true_reward, epochs=1, verbose)
  주어진 state에서 true reward를 예측하도록 학습한다.
  model.predict(state)
  unseen input에 대하여 reward를 예측한다.</p>
  </li>
  <li>
    <p><strong>action 선택</strong> (<code class="language-plaintext highlighter-rouge">choose_action()</code> 함수)</p>
  </li>
  <li>
    <p><strong>experience를 메모리에 저장</strong> (<code class="language-plaintext highlighter-rouge">store_transition()</code> 함수)</p>
  </li>
  <li>
    <p><strong>메모리의 experience를 이용하여 학습</strong> (<code class="language-plaintext highlighter-rouge">learn()</code> 함수)</p>
  </li>
</ul>

<p>이 과정을 통합하여 구현된 전체 DQN Class 코드는 아래와 같다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">EPISODES</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">DeepQLearning</span><span class="p">:</span>
   <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
           <span class="bp">self</span><span class="p">,</span>
           <span class="n">n_actions</span><span class="p">,</span>
           <span class="n">n_features</span><span class="p">,</span>
           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
           <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
           <span class="n">e_greedy</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
           <span class="n">replace_target_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
           <span class="n">memory_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
           <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span>
   <span class="p">):</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span> <span class="o">=</span> <span class="n">n_actions</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span> <span class="o">=</span> <span class="n">n_features</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">discount_factor</span> <span class="o">=</span> <span class="n">discount_factor</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">memory</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="n">memory_size</span><span class="p">)</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">e_greedy</span> <span class="o">=</span> <span class="n">e_greedy</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">replace_target_iter</span> <span class="o">=</span> <span class="n">replace_target_iter</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_construct_network</span><span class="p">()</span>

   <span class="k">def</span> <span class="nf">_construct_network</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>

       <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
       <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">24</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'relu'</span><span class="p">))</span>
       <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'linear'</span><span class="p">))</span>
       <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'mse'</span><span class="p">,</span>
                     <span class="n">optimizer</span><span class="o">=</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">))</span>
       <span class="k">return</span> <span class="n">model</span>

   <span class="k">def</span> <span class="nf">store_transition</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">next_s</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
       <span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">.</span><span class="n">append</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">next_s</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>

   <span class="k">def</span> <span class="nf">choose_action</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
       <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">])</span>
       <span class="k">if</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="p">.</span><span class="n">e_greedy</span><span class="p">:</span>
           <span class="k">return</span> <span class="n">random</span><span class="p">.</span><span class="n">randrange</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">n_actions</span><span class="p">)</span>
       <span class="n">act_values</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
       <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">act_values</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># returns action
</span>
   <span class="k">def</span> <span class="nf">learn</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
       <span class="n">minibatch</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">memory</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">)</span>
       <span class="k">for</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">done</span> <span class="ow">in</span> <span class="n">minibatch</span><span class="p">:</span>
           <span class="n">state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">])</span>
           <span class="n">next_state</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">next_state</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_features</span><span class="p">])</span>
           <span class="n">target</span> <span class="o">=</span> <span class="n">reward</span>
           <span class="k">if</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
               <span class="n">target</span> <span class="o">=</span> <span class="p">(</span><span class="n">reward</span> <span class="o">+</span> <span class="bp">self</span><span class="p">.</span><span class="n">discount_factor</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">amax</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">next_state</span><span class="p">)[</span><span class="mi">0</span><span class="p">]))</span>
           <span class="n">target_f</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
           <span class="n">target_f</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">action</span><span class="p">]</span> <span class="o">=</span> <span class="n">target</span>
           <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">target_f</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div>

<p> </p>
<h2 id="dqn-class-실행">DQN Class 실행</h2>
<p> </p>

<p>이제 이렇게 구현한 DQN Class를 활용하여 학습을 진행해보았다.
총 300개의 episode에 대하여 DQN을 학습시키고 average episode return을 그려보았다.
이 때, return 값이 새롭게 학습을 돌릴 때 마다 달라지기 때문에 300개의 episode로 학습하는 과정 전체를 5번 반복해서 episode reward의 min-max, mean를 나누어 plot하였다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="kn">from</span> <span class="nn">env</span> <span class="kn">import</span> <span class="n">Robot_Gridworld</span>
<span class="kn">from</span> <span class="nn">env2</span> <span class="kn">import</span> <span class="n">Robot_Gridworld</span> <span class="k">as</span> <span class="n">Robot_Gridworld2</span>
<span class="kn">from</span> <span class="nn">deep_q_learning</span> <span class="kn">import</span> <span class="n">DeepQLearning</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>

<span class="n">return_value</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.99</span>
<span class="n">episode_return_list</span><span class="o">=</span><span class="p">[]</span>
<span class="k">def</span> <span class="nf">update</span><span class="p">():</span>
   <span class="k">global</span> <span class="n">return_value</span>
   <span class="n">step</span> <span class="o">=</span> <span class="mi">0</span>
   <span class="n">reward_per_episode</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="n">returns</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

   <span class="k">for</span> <span class="n">episode</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span>

       <span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">reset</span><span class="p">()</span>
       <span class="n">step_count</span> <span class="o">=</span> <span class="mi">0</span>

       <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
           <span class="n">return_value</span> <span class="o">=</span> <span class="mi">0</span>
           <span class="n">env</span><span class="p">.</span><span class="n">render</span><span class="p">()</span>
           <span class="n">action</span> <span class="o">=</span> <span class="n">dqn</span><span class="p">.</span><span class="n">choose_action</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
           <span class="n">next_state</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">terminal</span> <span class="o">=</span> <span class="n">env</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
           <span class="n">return_value</span> <span class="o">=</span> <span class="n">reward</span> <span class="o">+</span> <span class="n">gamma</span> <span class="o">*</span> <span class="n">return_value</span>

           <span class="n">step_count</span> <span class="o">+=</span> <span class="mi">1</span>
           <span class="n">dqn</span><span class="p">.</span><span class="n">store_transition</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">next_state</span><span class="p">,</span> <span class="n">terminal</span><span class="p">)</span>

           <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">&gt;</span> <span class="mi">200</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">step</span> <span class="o">%</span> <span class="mi">5</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
               <span class="n">dqn</span><span class="p">.</span><span class="n">learn</span><span class="p">()</span>
           <span class="n">state</span> <span class="o">=</span> <span class="n">next_state</span>

           <span class="k">if</span> <span class="n">terminal</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
               <span class="k">print</span><span class="p">(</span><span class="s">" {} End. Total steps : {}</span><span class="se">\n</span><span class="s">"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">episode</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">step_count</span><span class="p">))</span>
               <span class="k">break</span>

           <span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>

       <span class="n">returns</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">return_value</span><span class="p">)</span>
       <span class="n">reward_per_episode</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">returns</span><span class="p">))</span>
   <span class="n">episode_return_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">reward_per_episode</span><span class="p">)</span>

   <span class="k">print</span><span class="p">(</span><span class="s">'Game over.</span><span class="se">\n</span><span class="s">'</span><span class="p">)</span>
   <span class="n">env</span><span class="p">.</span><span class="n">destroy</span><span class="p">()</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">"__main__"</span><span class="p">:</span>
   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
       <span class="n">env</span> <span class="o">=</span> <span class="n">Robot_Gridworld</span><span class="p">()</span>

       <span class="n">dqn</span> <span class="o">=</span> <span class="n">DeepQLearning</span><span class="p">(</span><span class="n">env</span><span class="p">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">env</span><span class="p">.</span><span class="n">n_features</span><span class="p">,</span>
                           <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                           <span class="n">discount_factor</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
                           <span class="n">e_greedy</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                           <span class="n">replace_target_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                           <span class="n">memory_size</span><span class="o">=</span><span class="mi">2000</span>
                           <span class="p">)</span>


       <span class="n">env</span><span class="p">.</span><span class="n">after</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">update</span><span class="p">)</span> <span class="c1">#Basic module in tkinter
</span>       <span class="n">env</span><span class="p">.</span><span class="n">mainloop</span><span class="p">()</span> <span class="c1">#Basic module in tkinter
</span>
   <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
   <span class="n">mean_return</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">episode_return_list</span><span class="p">).</span><span class="n">T</span><span class="p">]</span>
   <span class="n">min_return</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nb">min</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">episode_return_list</span><span class="p">).</span><span class="n">T</span><span class="p">]</span>
   <span class="n">max_return</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">episode_return_list</span><span class="p">).</span><span class="n">T</span><span class="p">]</span>
</code></pre></div></div>

<p>학습 결과는 다음과 같다.</p>

<ul>
  <li>첫번째 Gridworld (주황 네모 X)
    <div style="text-align: left">
  <img src="/assets/img/post_images/dqn1.png" width="100%" />
  </div>
  </li>
  <li>두번째 Gridworld (주황 네모 O)
    <div style="text-align: left">
  <img src="/assets/img/post_images/dqn2.png" width="100%" />
  </div>
  </li>
</ul>

                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
            

            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                    
                        <section class="author-card">
                            
                                <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Bean" />
                            
                            <section class="author-card-content">
                                <h4 class="author-card-name"><a href="/author/Bean">Beanie</a></h4>
                                
                                    <p>Hello, I’m Beanie, always pondering and crafting services to make life fun and convenient</p>
                                
                            </section>
                        </section>
                        <div class="post-full-footer-right">
                            <a class="author-card-button" href="/author/Bean">Read More</a>
                        </div>
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'http://localhost:4000/Implement-DQN';
                            var this_page_identifier = '/Implement DQN';
                            var this_page_title = 'Deep Q-Network(DQN) 구현';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://Beanie.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            

        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/img/style/bean3.jpg)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; PIGBEAN Tech blog &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/rl/">Rl</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/(RL)-Value-Function-Approximation">(Reinforcement learning) Value Function Approximation</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Implement-Q-learning-&-Double-Q-learning">Q-learning & Double Q-learning 구현</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5-%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0-1">RecSys & RL - A Deep Reinforcement Learning Framework for News Recommendation</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/rl/">
                                
                                    See all 5 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Transformer">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/ai_cover2.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Transformer">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Ai</span>
                            
                        
                    

                    <h2 class="post-card-title">Transformer</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Transformer은 recurrence나 convolution없이 attention만을 사용하는 새로운 sequence transduction model이다.

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Bean/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      4 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                

    <article class="post-card post-template">
        
            <a class="post-card-image-link" href="/Implement-Bidirectional-Associative-Memory">
                <div class="post-card-image" style="background-image: url(/assets/img/post_images/ai_cover2.jpg)"></div>
            </a>
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/Implement-Bidirectional-Associative-Memory">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Ai</span>
                            
                        
                    

                    <h2 class="post-card-title">Bidirectional Associative Memory 구현</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Bidirectional Associative Memory (BAM) 이란?

 
BAM 은 Hopfield model을 확장한 모델이다.
여기서 또 Hopfield model이라는 것이 등장하는 데(..), 잠시 정리하고 넘어가자.

</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
                    
                        
                        <img class="author-profile-image" src="/assets/img/style/beanie.png" alt="Beanie" />
                        
                        <span class="post-card-author">
                            <a href="/author/Bean/">Beanie</a>
                        </span>
                    
                
                <span class="reading-time">
                    
                    
                      6 min read
                    
                </span>
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="http://localhost:4000/">
            
                <img src="/assets/img/favicons/favicon-32x32.png" alt="PIGBEAN Tech blog icon" />
            
            <span>PIGBEAN Tech blog</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Deep Q-Network(DQN) 구현</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Deep+Q-Network%28DQN%29+%EA%B5%AC%ED%98%84&amp;url=https://beanie00.github.io/Implement-DQN"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://beanie00.github.io/Implement-DQN"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="http://localhost:4000/">PIGBEAN Tech blog</a> &copy; 2022</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                    <a href="https://ghost.org" target="_blank" rel="noopener">Ghost</a>
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-69281367-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
